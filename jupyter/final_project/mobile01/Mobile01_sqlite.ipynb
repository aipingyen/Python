{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests as r\n",
    "from  bs4 import BeautifulSoup\n",
    "from lib.toolbox import gen_header\n",
    "import time \n",
    "import random\n",
    "import json\n",
    "\n",
    "header_str = 'User-Agent:Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'\n",
    "HEADER = gen_header(header_str)\n",
    "carName_list = ['PORSCHE','NISSAN','TOYOTA','MITSUBISHI','HONDA','FORD','AUDI','MERCEDES BENZ','BMW','LEXUS','VOLKSWAGEN','MAZDA','SUBARU','SUZUKI','VOLVO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create db\n",
    "def creatDB():   \n",
    "    db = sqlite3.connect(\"./Mobile01.db\")\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"drop table Mobile01\")\n",
    "    cur.execute(\"create table Mobile01(url text,title text,author text,tm int,Board text,content text,reply_no int,replies text);\")\n",
    "    db.commit()\n",
    "creatDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pages of innerURL\n",
    "def contentPage(url):      \n",
    "    res = r.get(url,headers=HEADER)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    contentTag = soup.select(\".pagination > a\")\n",
    "    tagLen = len(contentTag)\n",
    "#     print(tagLen)\n",
    "    \n",
    "    if tagLen < 8:\n",
    "        contentPage = int(contentTag[3].text)\n",
    "    else :\n",
    "        contentPage = int(contentTag[tagLen-1].text)\n",
    "    return contentPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#num of totalArticle\n",
    "def reply_no(url):\n",
    "    contentURL = url+\"&p=\"+str(contentPage(url))\n",
    "#     print(contentPage(url))\n",
    "    reply_res = r.get(contentURL,headers=HEADER)\n",
    "    soup = BeautifulSoup(reply_res.text,'lxml')\n",
    "    reply_no = int(len(soup.select('main > article')))\n",
    "#     print(reply_no)\n",
    "    reply_id = int(soup.select('.date')[reply_no-1].text.split('\\xa0')[2][1:])\n",
    "    return reply_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#content od innerURL\n",
    "def getSubContent(url):\n",
    "    print(url)\n",
    "    replies = []\n",
    "    for page in range(1,contentPage(url)+1):    #此評論的所有的內頁\n",
    "        print(page)\n",
    "        contentURL = url+\"&p=\"+str(page)\n",
    "        print(contentURL)\n",
    "        time.sleep(int(random.random()*3+1))\n",
    "        reply_res = r.get(contentURL,headers=HEADER)\n",
    "        repli_soup = BeautifulSoup(reply_res.text,'lxml')\n",
    "        reply_no = int(len(repli_soup.select('main > article')))\n",
    "        print(\"article_no : \",reply_no)\n",
    "        while (reply_no > 0):\n",
    "            reply = {}\n",
    "            reply_id = int(repli_soup.select('.date')[reply_no-1].text.split('\\xa0')[2][1:])\n",
    "#             print(reply_id)\n",
    "            if reply_id != 1:\n",
    "                author_id = repli_soup.select('.fn > a')[reply_no-1].text\n",
    "#                 print(\"author_id\",author_id)\n",
    "\n",
    "                reply_time = repli_soup.select('.date')[reply_no-1].text.split('\\xa0')[0]\n",
    "                poTimeArray = time.strptime(reply_time, \"%Y-%m-%d %H:%M\")\n",
    "                tm = int(time.mktime(poTimeArray))\n",
    "#                 print(\"tm\",tm)\n",
    "\n",
    "                content = repli_soup.select('.single-post-content')[reply_no-1]\n",
    "                for blockquote in content.find_all('blockquote'):\n",
    "                    blockquote.decompose()\n",
    "                print(\"content : \\n\",content.text.strip())\n",
    "\n",
    "                reply[\"reply_id\"] = reply_id\n",
    "                reply[\"tm\"] = tm\n",
    "#                 reply[\"content\"] = content\n",
    "                reply[\"author_id\"] = str(author_id)\n",
    "                replies.append(reply)\n",
    "            reply_no -= 1\n",
    "    replies =  json.dumps(replies)\n",
    "\n",
    "    return replies\n",
    "# getSubContent(\"https://www.mobile01.com/topicdetail.php?f=346&t=2574949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(url):\n",
    "    conn = sqlite3.connect('./Mobile01.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    res = r.get(url,headers=HEADER)\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "\n",
    "    title = soup.select_one('.topic').text\n",
    "    print(\"title : \",title)\n",
    "\n",
    "    author = soup.select_one('.fn > a').text\n",
    "    print(\"author : \",author)\n",
    "\n",
    "    poTime = soup.select_one('.date').text.split('\\xa0')[0]\n",
    "    poTimeArray = time.strptime(poTime, \"%Y-%m-%d %H:%M\")\n",
    "    tm = int(time.mktime(poTimeArray))\n",
    "    print(\"tm : \",tm)\n",
    "\n",
    "    boardTag = soup.select('.nav > a')\n",
    "    Board = boardTag[3].text\n",
    "    print(\"Board : \",Board)\n",
    "\n",
    "    content = soup.select_one('.single-post-content').text\n",
    "    print(\"content : \",content)\n",
    "\n",
    "    reply = reply_no(url)\n",
    "    print(\"reply_no : \"+str(reply_no(url)))\n",
    "    \n",
    "    replies = getSubContent(url)\n",
    "    print(\"replies : \",replies)\n",
    "    try:\n",
    "        cursor.execute(\"INSERT into Mobile01 VALUES(?,?,?,?,?,?,?,?)\",\n",
    "                        (url, title, author, tm, Board, content, reply_no, replies))\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        conn.rollback()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.mobile01.com/topicdetail.php?f=606&t=4940549\n",
      "11\n",
      "title :  請問現在A6 35tfsi Avant折扣\n",
      "author :  bigeyes1205\n",
      "tm :  1475320560\n",
      "Board :  Audi\n",
      "content :  \n",
      "最近有想考慮換這台旅行車，不知道版上有沒有可以介紹比較優的菜單，最好是台中的，有看過版上討論可以折價53萬？不知道真的還假的？目前是開B6 1.8t avant 老了該換車了\n",
      "\n",
      "\n",
      "reply_no : 101\n",
      "https://www.mobile01.com/topicdetail.php?f=606&t=4940549\n"
     ]
    }
   ],
   "source": [
    "#take url from csv to function \n",
    "\n",
    "#for carName in carName_list:\n",
    "with open('./project/{}.csv'.format('AUDI'), 'r') as fr:\n",
    "    urls = fr.read().strip().split()\n",
    "    for url in urls:\n",
    "        print(url)\n",
    "        print(contentPage(url))\n",
    "        time.sleep(int(random.random()*3+1))\n",
    "        main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('./Mobile01.db')\n",
    "# cursor = conn.cursor()\n",
    "rows = conn.execute(\"SELECT * FROM Mobile01\")\n",
    "for row in rows:\n",
    "    print(row)\n",
    "conn.close()\n",
    "# def check_duplicates(content_dict):\n",
    "#     conn = sqlite3.connect('/home/ubuntu/python/III/Python/final_project/Crawler/icars.db')\n",
    "#     cursor = conn.cursor()\n",
    "\n",
    "#     title = content_dict['標題']\n",
    "#     color = content_dict['色系']\n",
    "#     cc = content_dict['排氣量']\n",
    "#     equip = content_dict['配備']\n",
    "#     location = content_dict['所在地']\n",
    "\n",
    "#     num = list(\n",
    "#         cursor.execute('SELECT * FROM icars WHERE title = ? AND cc = ? AND color = ?  AND equip = ? AND location = ?',\n",
    "#                        (title, cc, color, equip, location)))\n",
    "#     if num != 0:\n",
    "#         return False\n",
    "#     else:\n",
    "#         return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f8ba53f4445f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHEADER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import requests as r\n",
    "\n",
    "res = r.get(url,headers=HEADER)\n",
    "soup = BeautifulSoup(res.text,'lxml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
